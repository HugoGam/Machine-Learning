{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), 'target': array(['5', '0', '4', ..., '4', '5', '6'], dtype=object), 'feature_names': ['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7', 'pixel8', 'pixel9', 'pixel10', 'pixel11', 'pixel12', 'pixel13', 'pixel14', 'pixel15', 'pixel16', 'pixel17', 'pixel18', 'pixel19', 'pixel20', 'pixel21', 'pixel22', 'pixel23', 'pixel24', 'pixel25', 'pixel26', 'pixel27', 'pixel28', 'pixel29', 'pixel30', 'pixel31', 'pixel32', 'pixel33', 'pixel34', 'pixel35', 'pixel36', 'pixel37', 'pixel38', 'pixel39', 'pixel40', 'pixel41', 'pixel42', 'pixel43', 'pixel44', 'pixel45', 'pixel46', 'pixel47', 'pixel48', 'pixel49', 'pixel50', 'pixel51', 'pixel52', 'pixel53', 'pixel54', 'pixel55', 'pixel56', 'pixel57', 'pixel58', 'pixel59', 'pixel60', 'pixel61', 'pixel62', 'pixel63', 'pixel64', 'pixel65', 'pixel66', 'pixel67', 'pixel68', 'pixel69', 'pixel70', 'pixel71', 'pixel72', 'pixel73', 'pixel74', 'pixel75', 'pixel76', 'pixel77', 'pixel78', 'pixel79', 'pixel80', 'pixel81', 'pixel82', 'pixel83', 'pixel84', 'pixel85', 'pixel86', 'pixel87', 'pixel88', 'pixel89', 'pixel90', 'pixel91', 'pixel92', 'pixel93', 'pixel94', 'pixel95', 'pixel96', 'pixel97', 'pixel98', 'pixel99', 'pixel100', 'pixel101', 'pixel102', 'pixel103', 'pixel104', 'pixel105', 'pixel106', 'pixel107', 'pixel108', 'pixel109', 'pixel110', 'pixel111', 'pixel112', 'pixel113', 'pixel114', 'pixel115', 'pixel116', 'pixel117', 'pixel118', 'pixel119', 'pixel120', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131', 'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137', 'pixel138', 'pixel139', 'pixel140', 'pixel141', 'pixel142', 'pixel143', 'pixel144', 'pixel145', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel161', 'pixel162', 'pixel163', 'pixel164', 'pixel165', 'pixel166', 'pixel167', 'pixel168', 'pixel169', 'pixel170', 'pixel171', 'pixel172', 'pixel173', 'pixel174', 'pixel175', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel185', 'pixel186', 'pixel187', 'pixel188', 'pixel189', 'pixel190', 'pixel191', 'pixel192', 'pixel193', 'pixel194', 'pixel195', 'pixel196', 'pixel197', 'pixel198', 'pixel199', 'pixel200', 'pixel201', 'pixel202', 'pixel203', 'pixel204', 'pixel205', 'pixel206', 'pixel207', 'pixel208', 'pixel209', 'pixel210', 'pixel211', 'pixel212', 'pixel213', 'pixel214', 'pixel215', 'pixel216', 'pixel217', 'pixel218', 'pixel219', 'pixel220', 'pixel221', 'pixel222', 'pixel223', 'pixel224', 'pixel225', 'pixel226', 'pixel227', 'pixel228', 'pixel229', 'pixel230', 'pixel231', 'pixel232', 'pixel233', 'pixel234', 'pixel235', 'pixel236', 'pixel237', 'pixel238', 'pixel239', 'pixel240', 'pixel241', 'pixel242', 'pixel243', 'pixel244', 'pixel245', 'pixel246', 'pixel247', 'pixel248', 'pixel249', 'pixel250', 'pixel251', 'pixel252', 'pixel253', 'pixel254', 'pixel255', 'pixel256', 'pixel257', 'pixel258', 'pixel259', 'pixel260', 'pixel261', 'pixel262', 'pixel263', 'pixel264', 'pixel265', 'pixel266', 'pixel267', 'pixel268', 'pixel269', 'pixel270', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel275', 'pixel276', 'pixel277', 'pixel278', 'pixel279', 'pixel280', 'pixel281', 'pixel282', 'pixel283', 'pixel284', 'pixel285', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel290', 'pixel291', 'pixel292', 'pixel293', 'pixel294', 'pixel295', 'pixel296', 'pixel297', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel303', 'pixel304', 'pixel305', 'pixel306', 'pixel307', 'pixel308', 'pixel309', 'pixel310', 'pixel311', 'pixel312', 'pixel313', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel318', 'pixel319', 'pixel320', 'pixel321', 'pixel322', 'pixel323', 'pixel324', 'pixel325', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel332', 'pixel333', 'pixel334', 'pixel335', 'pixel336', 'pixel337', 'pixel338', 'pixel339', 'pixel340', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel347', 'pixel348', 'pixel349', 'pixel350', 'pixel351', 'pixel352', 'pixel353', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel360', 'pixel361', 'pixel362', 'pixel363', 'pixel364', 'pixel365', 'pixel366', 'pixel367', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel375', 'pixel376', 'pixel377', 'pixel378', 'pixel379', 'pixel380', 'pixel381', 'pixel382', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel389', 'pixel390', 'pixel391', 'pixel392', 'pixel393', 'pixel394', 'pixel395', 'pixel396', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel402', 'pixel403', 'pixel404', 'pixel405', 'pixel406', 'pixel407', 'pixel408', 'pixel409', 'pixel410', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel417', 'pixel418', 'pixel419', 'pixel420', 'pixel421', 'pixel422', 'pixel423', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel430', 'pixel431', 'pixel432', 'pixel433', 'pixel434', 'pixel435', 'pixel436', 'pixel437', 'pixel438', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel445', 'pixel446', 'pixel447', 'pixel448', 'pixel449', 'pixel450', 'pixel451', 'pixel452', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel457', 'pixel458', 'pixel459', 'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel464', 'pixel465', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel473', 'pixel474', 'pixel475', 'pixel476', 'pixel477', 'pixel478', 'pixel479', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel485', 'pixel486', 'pixel487', 'pixel488', 'pixel489', 'pixel490', 'pixel491', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel500', 'pixel501', 'pixel502', 'pixel503', 'pixel504', 'pixel505', 'pixel506', 'pixel507', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517', 'pixel518', 'pixel519', 'pixel520', 'pixel521', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel527', 'pixel528', 'pixel529', 'pixel530', 'pixel531', 'pixel532', 'pixel533', 'pixel534', 'pixel535', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel542', 'pixel543', 'pixel544', 'pixel545', 'pixel546', 'pixel547', 'pixel548', 'pixel549', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel555', 'pixel556', 'pixel557', 'pixel558', 'pixel559', 'pixel560', 'pixel561', 'pixel562', 'pixel563', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel570', 'pixel571', 'pixel572', 'pixel573', 'pixel574', 'pixel575', 'pixel576', 'pixel577', 'pixel578', 'pixel579', 'pixel580', 'pixel581', 'pixel582', 'pixel583', 'pixel584', 'pixel585', 'pixel586', 'pixel587', 'pixel588', 'pixel589', 'pixel590', 'pixel591', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel599', 'pixel600', 'pixel601', 'pixel602', 'pixel603', 'pixel604', 'pixel605', 'pixel606', 'pixel607', 'pixel608', 'pixel609', 'pixel610', 'pixel611', 'pixel612', 'pixel613', 'pixel614', 'pixel615', 'pixel616', 'pixel617', 'pixel618', 'pixel619', 'pixel620', 'pixel621', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel629', 'pixel630', 'pixel631', 'pixel632', 'pixel633', 'pixel634', 'pixel635', 'pixel636', 'pixel637', 'pixel638', 'pixel639', 'pixel640', 'pixel641', 'pixel642', 'pixel643', 'pixel644', 'pixel645', 'pixel646', 'pixel647', 'pixel648', 'pixel649', 'pixel650', 'pixel651', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel657', 'pixel658', 'pixel659', 'pixel660', 'pixel661', 'pixel662', 'pixel663', 'pixel664', 'pixel665', 'pixel666', 'pixel667', 'pixel668', 'pixel669', 'pixel670', 'pixel671', 'pixel672', 'pixel673', 'pixel674', 'pixel675', 'pixel676', 'pixel677', 'pixel678', 'pixel679', 'pixel680', 'pixel681', 'pixel682', 'pixel683', 'pixel684', 'pixel685', 'pixel686', 'pixel687', 'pixel688', 'pixel689', 'pixel690', 'pixel691', 'pixel692', 'pixel693', 'pixel694', 'pixel695', 'pixel696', 'pixel697', 'pixel698', 'pixel699', 'pixel700', 'pixel701', 'pixel702', 'pixel703', 'pixel704', 'pixel705', 'pixel706', 'pixel707', 'pixel708', 'pixel709', 'pixel710', 'pixel711', 'pixel712', 'pixel713', 'pixel714', 'pixel715', 'pixel716', 'pixel717', 'pixel718', 'pixel719', 'pixel720', 'pixel721', 'pixel722', 'pixel723', 'pixel724', 'pixel725', 'pixel726', 'pixel727', 'pixel728', 'pixel729', 'pixel730', 'pixel731', 'pixel732', 'pixel733', 'pixel734', 'pixel735', 'pixel736', 'pixel737', 'pixel738', 'pixel739', 'pixel740', 'pixel741', 'pixel742', 'pixel743', 'pixel744', 'pixel745', 'pixel746', 'pixel747', 'pixel748', 'pixel749', 'pixel750', 'pixel751', 'pixel752', 'pixel753', 'pixel754', 'pixel755', 'pixel756', 'pixel757', 'pixel758', 'pixel759', 'pixel760', 'pixel761', 'pixel762', 'pixel763', 'pixel764', 'pixel765', 'pixel766', 'pixel767', 'pixel768', 'pixel769', 'pixel770', 'pixel771', 'pixel772', 'pixel773', 'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780', 'pixel781', 'pixel782', 'pixel783', 'pixel784'], 'DESCR': \"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\", 'details': {'id': '554', 'name': 'mnist_784', 'version': '1', 'format': 'ARFF', 'upload_date': '2014-09-29T03:28:38', 'licence': 'Public', 'url': 'https://www.openml.org/data/v1/download/52667/mnist_784.arff', 'file_id': '52667', 'default_target_attribute': 'class', 'tag': ['AzurePilot', 'OpenML-CC18', 'OpenML100', 'study_1', 'study_123', 'study_41', 'study_99', 'vision'], 'visibility': 'public', 'status': 'active', 'processing_date': '2018-10-03 21:23:30', 'md5_checksum': '0298d579eb1b86163de7723944c7e495'}, 'categories': {}, 'url': 'https://www.openml.org/d/554'}\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['5' '0' '4' ... '4' '5' '6']\n",
      "Help on built-in function len in module builtins:\n",
      "\n",
      "len(obj, /)\n",
      "    Return the number of items in a container.\n",
      "\n",
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mnist)\n",
    "print(mnist.data)\n",
    "print(mnist.target)\n",
    "len(mnist.data)\n",
    "help(len)\n",
    "print(mnist.data.shape)\n",
    "print(mnist.target.shape)\n",
    "mnist.data[0]\n",
    "mnist.data[0][1]\n",
    "mnist.data[:,1]\n",
    "mnist.data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "#Affiche le format des données\n",
    "print(mnist.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#Affiche l'étiquette du premier chiffre de la base de donnée\n",
    "print(mnist.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les donneés contenues dans mnist.data sont dans le format (70000, 784)\n",
    "# Pour les mettre dans le format original, c'est-à-dire, comme une image\n",
    "# 28x28 pixels, il faut utiliser le commande reshape.\n",
    "images = mnist.data.reshape((-1, 28, 28))\n",
    "# le \"-1\" est necessaire pour qu'on transforme que la colonne du mnist.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#On cherche maintenant à visualiser le premier chiffre de la base\n",
    "#de données, d'où le image[0]\n",
    "plt.imshow(images[0],cmap=plt.cm.gray_r,interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autre jeux de données Iris\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "#Renvoie une description générale du jeu de données\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "#Affiche les 3 catégories/espèces de fleurs\n",
    "print(iris.target_names)\n",
    "#Donne les caractéristiques évaluées\n",
    "print(iris.feature_names)\n",
    "#Affiche le format des data contenant 150 données\n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualisation des données\n",
    "X = iris.data[:,:2]\n",
    "y = (iris.target != 0)*1\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='g', label='0')\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='y', label='1')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breast_cancer dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "['malignant' 'benign']\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "#Donne une description du dataset sur le cancer du sein\n",
    "print(cancer.DESCR)\n",
    "\n",
    "#renvoie les deux types de tumeurs : maligne ou bénigne\n",
    "print(cancer.target_names)\n",
    "#renvoie tous les noms des attributs qu'il faut vérifier (30)\n",
    "print(cancer.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "#affichage des données et des étiquettes\n",
    "print(cancer.data)\n",
    "print(cancer.target)\n",
    "print(cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset sur les vins\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "#Description globale du dataset\n",
    "print(wine.DESCR)\n",
    "\n",
    "#Affiche les différents paramètres des vins\n",
    "print(wine.feature_names)\n",
    "\n",
    "#Donne les 3 classes du dataset\n",
    "print(wine.target_names)\n",
    "\n",
    "#Renvoie la taille des données 178x13\n",
    "print(wine.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries pour la méthode k-nn\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donnée prédite  ['0']\n",
      "Vraie donnée  0\n",
      "Précision  0.904\n"
     ]
    }
   ],
   "source": [
    "#exercice 2 methode k-nn\n",
    "\n",
    "sample = np.random.randint(70000, size=5000)\n",
    "data = mnist.data[sample]\n",
    "target = mnist.target[sample]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data,target,train_size = 0.8)\n",
    "clf = neighbors.KNeighborsClassifier (n_neighbors = 10)\n",
    "clf.fit(xtrain,ytrain)\n",
    "\n",
    "#prédition de la classe prédite de l'image 4\n",
    "# xtest est une nouvelle donnée\n",
    "#avec predict(), le classfieur k-nn va donner l'étiquette qu'il pense\n",
    "print(\"Donnée prédite \",clf.predict([xtest[4]]))\n",
    "# vrai valeur (la vérité qu'on compare avec la valeur prédite)\n",
    "print(\"Vraie donnée \",ytest[4])\n",
    "#préicision sur la classification\n",
    "print(\"Précision \",clf.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOXklEQVR4nO3dbayU9ZnH8d8lS00ETGDPAU8o7mEbXyzZKNQJmohE02wDvkFedAORBxPNaaKYVpv4UFTkjRizLWzihoSnlN2gtbHlIcSUGmxieGHDqKw82YqGLQcJHAJRqpF66LUvzk1zwDP/e5i5Z+7B6/tJJjNzXzPnf2Xgd+6Z+z/n/pu7C8A33zVlNwCgPQg7EARhB4Ig7EAQhB0I4h/aOVhXV5f39va2c0gglKNHj+r06dM2Uq2psJvZHEn/KWmUpA3u/kLq8b29vapWq80MCSChUqnUrDX8Nt7MRkn6L0lzJU2TtNDMpjX68wC0VjOf2WdKOuLuH7v7XyX9UtK8YtoCULRmwj5Z0rFh9/uzbZcwsz4zq5pZdWBgoInhADSjmbCPdBDga9+9dfd17l5x90p3d3cTwwFoRjNh75c0Zdj9b0v6pLl2ALRKM2HfK+kmM5tqZt+StEDSjmLaAlC0hqfe3H3QzJZJ2qWhqbdN7n6wsM4AFKqpeXZ3f13S6wX1AqCF+LosEARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0G0dclmdJ5Dhw4l62vWrEnW169fn6wvXLiwZi214qgkPfbYY8k6rgx7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Iwty9bYNVKhWvVqttGw/S5s2bk/VnnnkmWe/v7y+ynSvS1dWVrN9+++3J+pYtW2rWxo0b11BPna5SqahardpItaa+VGNmRyWdk3RB0qC7p78lAaA0RXyD7m53P13AzwHQQnxmB4JoNuwu6Xdm9o6Z9Y30ADPrM7OqmVUHBgaaHA5Ao5oN+x3u/l1JcyU9bGazL3+Au69z94q7V7q7u5scDkCjmgq7u3+SXZ+StFXSzCKaAlC8hsNuZmPMbNzF25K+L+lAUY0BKFYzR+MnSdpqZhd/zsvu/ttCusIlvvrqq2R9165dNWt9fSMeSqn7Z5fp9On0JM/OnTuT9VtvvbVm7bXXXks+9+abb07Wr0YNh93dP5Z0S4G9AGghpt6AIAg7EARhB4Ig7EAQhB0IglNJd4Avv/wyWV++fHmyvnr16iLb+cY4cuRIzdrKlSuTz92wYUOyPn78+IZ6KhN7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Ignn2NsibR887nfM3dR4978xFg4ODyfrZs2cbHnvr1q3Jet4p1vNO0d2Jp6pmzw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDPXoC9e/cm66tWrUrWt23bVmQ7bTVmzJhkffHixTVrDz30UPK5eXPhK1asSNabkfdvsmjRomR9+/btRbZTCPbsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE8+wFWLp0abL+wQcftKmT4i1btixZf/TRR5P1qVOnNjx23t+rX3vttcn6+fPnGx47z5tvvpms79mzJ1mfNWtWke3UJXfPbmabzOyUmR0Ytm2Cmb1hZh9m11ffGfOBYOp5G/8LSXMu2/akpN3ufpOk3dl9AB0sN+zu/pakM5dtnifp4nl5Nku6t+C+ABSs0QN0k9z9hCRl1xNrPdDM+sysambVgYGBBocD0KyWH41393XuXnH3St4JBgG0TqNhP2lmPZKUXZ8qriUArdBo2HdIujjftFRS5/09H4BL5M6zm9krku6S1GVm/ZJWSHpB0q/M7AFJf5b0g1Y2idZ58MEHk/UnnngiWZ88eXKR7VzizjvvTNZ37dqVrM+bN69m7dNPP22op4s+//zzZP3tt99O1suYZ88Nu7svrFH6XsG9AGghvi4LBEHYgSAIOxAEYQeCIOxAEPyJa50++uijmrVz5861sZOve/zxx2vWHnnkkeRzb7jhhmR91KhRDfXUDrNnz07WJ0yYULPW7NTb1Yg9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTx7nTZu3Fizdvz48ZaOPWPGjGQ9dTrnSZMmFd0OrlLs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCObZ67Rhw4bSxu7r60vWmUtvv9GjRyfrEyfWXBGtNOzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAI5tkzeed+v3DhQsvGzpuzHTNmTMvGRmPGjx+frC9ZsqRNndQvd89uZpvM7JSZHRi27TkzO25m+7LLPa1tE0Cz6nkb/wtJc0bYvtrdp2eX14ttC0DRcsPu7m9JOtOGXgC0UDMH6JaZ2fvZ2/yaH2DMrM/MqmZWHRgYaGI4AM1oNOxrJX1H0nRJJyT9rNYD3X2du1fcvdLd3d3gcACa1VDY3f2ku19w979JWi9pZrFtAShaQ2E3s55hd+dLOlDrsQA6Q+48u5m9IukuSV1m1i9phaS7zGy6JJd0VNIPW9hjW6xduzZZP3v2bMvGvvHGG5P1RYsWtWzsTjY4OJisL1++PFk/c6Z1x5Wvuebq+z5abtjdfeEIm2uvmACgI119v54ANISwA0EQdiAIwg4EQdiBIPgTV5Qmb2pt7ty5yfru3buLbOeKPP/886WN3Sj27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBPPsHeCzzz5L1g8dOpSsT5s2rch2rsjOnTuT9YMHD9as5c1V553eu5Xuv//+ZP2+++5rTyMFYs8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewz94B8pbFuvvuu5P1sWPH1qytWrUq+dz9+/cn6y+//HKyfvLkyWT9iy++SNbLcttttyXrL730UrKet8x2J2LPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM+eWbx4cbL+6quv1qy99957Rbdzibx5+FR9wYIFRbdz1UjNpa9cuTL53Ouuu67odkqXu2c3sylm9nszO2xmB83sR9n2CWb2hpl9mF2Pb327ABpVz9v4QUk/cfd/kXS7pIfNbJqkJyXtdvebJO3O7gPoULlhd/cT7v5udvucpMOSJkuaJ2lz9rDNku5tVZMAmndFB+jMrFfSDEl/kDTJ3U9IQ78QJE2s8Zw+M6uaWTXvsyeA1qk77GY2VtKvJf3Y3dNnSBzG3de5e8XdK93d3Y30CKAAdYXdzEZrKOhb3P032eaTZtaT1XsknWpNiwCKkDv1ZmYmaaOkw+7+82GlHZKWSnohu97ekg7bpKenJ1nftm1bzdqsWbOSzz127FhDPUWX905w7dq1yfqcOXNq1r6JU2t56plnv0PSYkn7zWxftu2nGgr5r8zsAUl/lvSD1rQIoAi5YXf3PZKsRvl7xbYDoFX4uiwQBGEHgiDsQBCEHQiCsANB8CeudZoyZUrN2po1a5LPffHFF5P1ffv2Jevnz59P1suUd0rl3t7emrWnnnoq+dxbbrklWZ8xY0ayjkuxZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIJhnL8D8+fObqm/fnj4VQN6yys8++2yynvL0008n69dff32yPnHiiGcj+7slS5ZccU9oDfbsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxCEuXvbBqtUKl6tVts2HhBNpVJRtVod8WzQ7NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IIjcsJvZFDP7vZkdNrODZvajbPtzZnbczPZll3ta3y6ARtVz8opBST9x93fNbJykd8zsjay22t3/o3XtAShKPeuzn5B0Irt9zswOS5rc6sYAFOuKPrObWa+kGZL+kG1aZmbvm9kmMxtf4zl9ZlY1s+rAwEBTzQJoXN1hN7Oxkn4t6cfu/pmktZK+I2m6hvb8Pxvpee6+zt0r7l7p7u4uoGUAjagr7GY2WkNB3+Luv5Ekdz/p7hfc/W+S1kua2bo2ATSrnqPxJmmjpMPu/vNh23uGPWy+pAPFtwegKPUcjb9D0mJJ+83s4trCP5W00MymS3JJRyX9sCUdAihEPUfj90ga6e9jXy++HQCtwjfogCAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQbR1yWYzG5D0f8M2dUk63bYGrkyn9tapfUn01qgie/sndx/x/G9tDfvXBjerunultAYSOrW3Tu1LordGtas33sYDQRB2IIiyw76u5PFTOrW3Tu1LordGtaW3Uj+zA2ifsvfsANqEsANBlBJ2M5tjZn80syNm9mQZPdRiZkfNbH+2DHW15F42mdkpMzswbNsEM3vDzD7MrkdcY6+k3jpiGe/EMuOlvnZlL3/e9s/sZjZK0p8k/Zukfkl7JS1090NtbaQGMzsqqeLupX8Bw8xmS/qLpP9293/Ntr0o6Yy7v5D9ohzv7k90SG/PSfpL2ct4Z6sV9QxfZlzSvZLuV4mvXaKvf1cbXrcy9uwzJR1x94/d/a+SfilpXgl9dDx3f0vSmcs2z5O0Obu9WUP/WdquRm8dwd1PuPu72e1zki4uM17qa5foqy3KCPtkSceG3e9XZ6337pJ+Z2bvmFlf2c2MYJK7n5CG/vNImlhyP5fLXca7nS5bZrxjXrtGlj9vVhlhH2kpqU6a/7vD3b8raa6kh7O3q6hPXct4t8sIy4x3hEaXP29WGWHvlzRl2P1vS/qkhD5G5O6fZNenJG1V5y1FffLiCrrZ9amS+/m7TlrGe6RlxtUBr12Zy5+XEfa9km4ys6lm9i1JCyTtKKGPrzGzMdmBE5nZGEnfV+ctRb1D0tLs9lJJ20vs5RKdsox3rWXGVfJrV/ry5+7e9oukezR0RP4jScvL6KFGX/8s6X+zy8Gye5P0iobe1n2loXdED0j6R0m7JX2YXU/ooN7+R9J+Se9rKFg9JfU2S0MfDd+XtC+73FP2a5foqy2vG1+XBYLgG3RAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMT/A2FoT9Ce4PzaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#représentation de la donnée prédite\n",
    "image_test = xtest.reshape((-1, 28, 28))\n",
    "plt.imshow(image_test[4],cmap=plt.cm.gray_r,interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 0.942Best k : 3\n"
     ]
    }
   ],
   "source": [
    "#Variation du nb de voisins de 2 à 15\n",
    "best_acc = 0\n",
    "kBest = 0\n",
    "for k in range(2,16):\n",
    "    for i in range(5):\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(data,target,train_size = 0.8)\n",
    "        clf = neighbors.KNeighborsClassifier (n_neighbors = k)\n",
    "        clf.fit(xtrain,ytrain)\n",
    "        acc = clf.score(xtest,ytest)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            kBest = k\n",
    "print(\"Best Accuracy : \" + str(best_acc) + \" Best k : \" + str(kBest))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_size = 5000 score_test = 0.923\n",
      "Sample_size = 10000 score_test = 0.928\n",
      "Sample_size = 15000 score_test = 0.936\n",
      "Sample_size = 20000 score_test = 0.93\n",
      "Sample_size = 25000 score_test = 0.923\n",
      "Sample_size = 30000 score_test = 0.934\n",
      "Sample_size = 35000 score_test = 0.925\n",
      "Sample_size = 40000 score_test = 0.925\n",
      "Sample_size = 45000 score_test = 0.931\n",
      "Sample_size = 50000 score_test = 0.928\n",
      "Sample_size = 55000 score_test = 0.931\n",
      "Sample_size = 60000 score_test = 0.922\n",
      "Sample_size = 65000 score_test = 0.918\n"
     ]
    }
   ],
   "source": [
    "#Variation de la taille de l'échantillon total\n",
    "k_range = [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000,50000, 55000,60000,65000]\n",
    "for i in k_range:\n",
    "    sample2 = np.random.randint(70000, size=i)\n",
    "    data2 = mnist.data[sample]\n",
    "    target2 = mnist.target[sample]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(data2,target2,train_size = 0.8)\n",
    "    clf = neighbors.KNeighborsClassifier (n_neighbors = 3)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    acc_test = clf.score(xtest,ytest)\n",
    "    print(\"Sample_size = \" + str(i)+ \" score_test = \"+ str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variation de la taille de l'échantillon training\n",
    "#taille échantillon 5 000\n",
    "sample3 = np.random.randint(70000, size=5000)\n",
    "data3 = mnist.data[sample]\n",
    "target3 = mnist.target[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size = 0.1 score_test = 0.8282222222222222 score_train = 0.932\n",
      "train_size = 0.2 score_test = 0.8735 score_train = 0.94\n",
      "train_size = 0.3 score_test = 0.894 score_train = 0.946\n",
      "train_size = 0.4 score_test = 0.9073333333333333 score_train = 0.9485\n",
      "train_size = 0.5 score_test = 0.9068 score_train = 0.9536\n",
      "train_size = 0.6 score_test = 0.915 score_train = 0.9606666666666667\n",
      "train_size = 0.7 score_test = 0.928 score_train = 0.9591428571428572\n",
      "train_size = 0.8 score_test = 0.924 score_train = 0.961\n",
      "train_size = 0.9 score_test = 0.932 score_train = 0.9635555555555556\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,10):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(data3,target3,train_size = k/10)\n",
    "    clf = neighbors.KNeighborsClassifier (n_neighbors = 3)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    acc_test = clf.score(xtest,ytest)\n",
    "    acc_train = clf.score(xtrain,ytrain)\n",
    "    print(\"train_size = \"+str(k/10) + \" score_test = \" + str(acc_test)+ \" score_train = \"+str(acc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision avec manhattan_distance : 0.918\n",
      "Précision avec euclidean_distance : 0.929\n"
     ]
    }
   ],
   "source": [
    "#Variation des types de distances (p)\n",
    "sample = np.random.randint(70000, size=5000)\n",
    "data = mnist.data[sample]\n",
    "target = mnist.target[sample]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data,target,train_size = 0.8)\n",
    "\n",
    "#Manhattan distance\n",
    "clf1 = neighbors.KNeighborsClassifier (n_neighbors = 3, p=1)\n",
    "clf1.fit(xtrain,ytrain)\n",
    "acc_manh = clf1.score(xtest,ytest)\n",
    "\n",
    "#Euclidean distance (default)\n",
    "clf2 = neighbors.KNeighborsClassifier (n_neighbors = 3, p=2)\n",
    "clf2.fit(xtrain,ytrain)\n",
    "acc_eucli = clf2.score(xtest,ytest)\n",
    "\n",
    "print(\"Précision avec manhattan_distance : \"+str(acc_manh))\n",
    "print(\"Précision avec euclidean_distance : \"+str(acc_eucli))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p =  3  acc =  0.935\n",
      "p =  4  acc =  0.934\n",
      "p =  5  acc =  0.935\n",
      "p =  6  acc =  0.933\n",
      "p =  7  acc =  0.934\n"
     ]
    }
   ],
   "source": [
    "#Test avec d'autres valeurs de p de 3 à 7\n",
    "for i in range(3,8):\n",
    "    clf = neighbors.KNeighborsClassifier (n_neighbors = 3, p=i)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    acc = clf.score(xtest,ytest)\n",
    "    print(\"p = \",i,\" acc = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps avec n_job =1 ---> 0.12911701202392578 s\n",
      "Temps avec n_job = -1 ---> 0.1090998649597168 s\n"
     ]
    }
   ],
   "source": [
    "#n job variation\n",
    "import time\n",
    "\n",
    "sample = np.random.randint(70000, size=5000)\n",
    "data = mnist.data[sample]\n",
    "target = mnist.target[sample]\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data,target,train_size = 0.8)\n",
    "\n",
    "#calcul du temps pour n_job =1\n",
    "seconds = time.time()\n",
    "clf1 = neighbors.KNeighborsClassifier(n_neighbors=3, n_jobs=1)\n",
    "clf1.fit(xtrain,ytrain)\n",
    "seconds2=time.time()\n",
    "print(\"Temps avec n_job =1 --->\",seconds2-seconds,\"s\")\n",
    "\n",
    "\n",
    "#calcul du temps pour n_job=-1\n",
    "seconds = time.time()\n",
    "clf2 = neighbors.KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf2.fit(xtrain,ytrain)\n",
    "seconds2=time.time()\n",
    "print(\"Temps avec n_job = -1 --->\",seconds2-seconds,\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
